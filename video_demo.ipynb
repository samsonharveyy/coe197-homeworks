{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv1ktJBLzdixSc2gibDsy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b13eddcf1f84994857c38f6a0d73501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f93091513c4eda85414d8a75599132",
              "IPY_MODEL_31bc89d664b54bd18c8e3d30d10c4718",
              "IPY_MODEL_91c9ac37d4a54fb8bec3f1a2b8151b9d"
            ],
            "layout": "IPY_MODEL_31e49209f611491593e52d3387cf3041"
          }
        },
        "44f93091513c4eda85414d8a75599132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d5c621d1a846fa8fb7796cf962dc95",
            "placeholder": "​",
            "style": "IPY_MODEL_4fbbf86c29ea4beea4b47341ccbb8476",
            "value": "100%"
          }
        },
        "31bc89d664b54bd18c8e3d30d10c4718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a41af4256c4b349763cfc84276c78c",
            "max": 77844807,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a94aabb6374e1e967c75fa3ada2ac0",
            "value": 77844807
          }
        },
        "91c9ac37d4a54fb8bec3f1a2b8151b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b2cee55d5d467b8db6837f68426626",
            "placeholder": "​",
            "style": "IPY_MODEL_4f081ea3b5b549bca1d445d72c285731",
            "value": " 74.2M/74.2M [00:00&lt;00:00, 117MB/s]"
          }
        },
        "31e49209f611491593e52d3387cf3041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d5c621d1a846fa8fb7796cf962dc95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fbbf86c29ea4beea4b47341ccbb8476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a41af4256c4b349763cfc84276c78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a94aabb6374e1e967c75fa3ada2ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1b2cee55d5d467b8db6837f68426626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f081ea3b5b549bca1d445d72c285731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsonharveyy/object-detection/blob/master/video_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rpyq_QZj5Mb",
        "outputId": "9cd6f4ec-4021-4c8b-98f9-2dd233d2608e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch -U\n",
        "!pip install torchvision -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J31xz0w8kfXg",
        "outputId": "8269ed84-d61a-485a-ef2f-937572ba6e75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgm4kww4kgvF",
        "outputId": "6ea6776d-7cc2-4b5f-99c9-3fc734f3e5b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113 False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlnQBGKMmDRG",
        "outputId": "5cd59806-4400-470a-d22c-19234656043a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import tarfile\n",
        "\n",
        "#download pretrained weights \n",
        "#function also found as download_trained() in download.py in repo\n",
        "def download_trained():\n",
        "    #single file, no extraction\n",
        "    #(for 60 epochs only)\n",
        "    #gdown.download(\"https://drive.google.com/uc?id=18q5n_IUcjeOrMf6q2LIX_MvD2ee6bsZm\", \"drinks-trained-weights.pth\", quiet=False)\n",
        "\n",
        "    #updated version, 80 epochs\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1yF7MCj116-hc16xshxBjaJgU9zT_by8C\", \"drinks-trained-weights.pth\", quiet=False)\n",
        "\n",
        "def download_\n",
        "\n",
        "download_trained()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HtYayMtkji1",
        "outputId": "b6b1cda5-ff76-42d9-b7ce-1e22a30451c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yF7MCj116-hc16xshxBjaJgU9zT_by8C\n",
            "To: /content/drinks-trained-weights.pth\n",
            "100%|██████████| 76.1M/76.1M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#py files from my repo to help with object detection\n",
        "import sys \n",
        "sys.path.insert(0,\"/content/drive/My Drive/detection_files\")"
      ],
      "metadata": {
        "id": "QxOCX4fjnvh_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from download import download_data\n",
        "#from download import download_trained\n",
        "import os\n",
        "\n",
        "#need to upload model_helper.py from repo to Colab\n",
        "from model_helper import segment\n",
        "from model_helper import ImageDataset\n",
        "\n",
        "#need to upload other .py files from repo\n",
        "#i added it to a folder in my drive called detection_files\n",
        "import engine\n",
        "import utils\n",
        "import label_utils\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def main():\n",
        "\n",
        "    if not os.path.exists(\"/content/drinks-trained-weights.pth\"):\n",
        "        download_trained()\n",
        "\n",
        "    #for Google Colab (need to change path)\n",
        "    labels_test_path = \"/content/drive/My Drive/drinks/labels_test.csv\"\n",
        "    labels_train_path = \"/content/drive/My Drive/drinks/labels_train.csv\"\n",
        "    #labels_test_path = \"drinks/labels_test.csv\"\n",
        "    #labels_train_path = \"drinks/labels_train.csv\"\n",
        "    test_dict, test_classes = label_utils.build_label_dictionary(labels_test_path)\n",
        "    train_dict, train_classes = label_utils.build_label_dictionary(labels_train_path)\n",
        "    \n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    num_classes = 4\n",
        "    test_split = ImageDataset(test_dict, transforms.ToTensor())\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_split, \n",
        "        batch_size = 1, \n",
        "        shuffle = False, \n",
        "        num_workers = 2,\n",
        "        collate_fn = utils.collate_fn)\n",
        "\n",
        "    model = segment(num_classes)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      #for google colab\n",
        "      model.load_state_dict(torch.load(\"/content/drinks-trained-weights.pth\"))\n",
        "      #model.load_state_dict(torch.load(\"drinks-trained-weights.pth\"))\n",
        "    else:\n",
        "      #for google colab\n",
        "      model.load_state_dict(torch.load(\"/content/drinks-trained-weights.pth\", map_location=torch.device(\"cpu\")))\n",
        "      #model.load_state_dict(torch.load(\"drinks-trained-weights.pth\", map_location=torch.device(\"cpu\")))\n",
        "\n",
        "    #use either gpu or cpu\n",
        "    model.to(device)\n",
        "\n",
        "    #test model performance evaluation\n",
        "    engine.evaluate(model, test_loader, device = device)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "7b13eddcf1f84994857c38f6a0d73501",
            "44f93091513c4eda85414d8a75599132",
            "31bc89d664b54bd18c8e3d30d10c4718",
            "91c9ac37d4a54fb8bec3f1a2b8151b9d",
            "31e49209f611491593e52d3387cf3041",
            "75d5c621d1a846fa8fb7796cf962dc95",
            "4fbbf86c29ea4beea4b47341ccbb8476",
            "97a41af4256c4b349763cfc84276c78c",
            "f0a94aabb6374e1e967c75fa3ada2ac0",
            "d1b2cee55d5d467b8db6837f68426626",
            "4f081ea3b5b549bca1d445d72c285731"
          ]
        },
        "id": "qTk_aigJkpw1",
        "outputId": "b4795549-854f-43d1-c200-e3e675ef00d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_320_fpn-907ea3f9.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_320_fpn-907ea3f9.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/74.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b13eddcf1f84994857c38f6a0d73501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/51]  eta: 0:00:24  model_time: 0.3754 (0.3754)  evaluator_time: 0.0030 (0.0030)  time: 0.4796  data: 0.1008\n",
            "Test:  [50/51]  eta: 0:00:00  model_time: 0.1431 (0.1529)  evaluator_time: 0.0016 (0.0017)  time: 0.1495  data: 0.0041\n",
            "Test: Total time: 0:00:08 (0.1623 s / it)\n",
            "Averaged stats: model_time: 0.1431 (0.1529)  evaluator_time: 0.0016 (0.0017)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.817\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.924\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/opencv/opencv.git\n",
        "!mkdir Video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVcrj_VNk3pu",
        "outputId": "c216f10e-486b-43a1-e8d5-3752dd32a5c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'opencv'...\n",
            "remote: Enumerating objects: 305219, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 305219 (delta 0), reused 0 (delta 0), pack-reused 305207\u001b[K\n",
            "Receiving objects: 100% (305219/305219), 494.40 MiB | 27.83 MiB/s, done.\n",
            "Resolving deltas: 100% (212416/212416), done.\n",
            "Checking out files: 100% (7045/7045), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python\n",
        "\n",
        "\n",
        "from IPython.display import HTML, Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "video_file_test = '/content/Video/test.mp4' \n",
        "  \n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var my_btn_txt = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(my_btn_txt);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, videoStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  videoStream = stream;\n",
        "  var options = {  \n",
        "    mimeType : 'video/webm;codecs=vp9'  \n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('video');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      videoStream.getVideoTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... Please wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      \n",
        "      return;\n",
        "\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "  \n",
        "    \n",
        "start_webcam()\n",
        "\n",
        "def get_video():\n",
        "  display(HTML(VIDEO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  return binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "cLUXm_-vk5mt",
        "outputId": "51b57e15-0943-4957-8713-53ed5c5c28de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function startWebcam() {\n",
              "      const div = document.createElement('div');\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "      \n",
              "      return;\n",
              "\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "videofile = get_video()\n",
        "\n",
        "with open(video_file_test, 'wb') as f:\n",
        "  f.write(videofile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "_UAOhSZ2k-XP",
        "outputId": "0df1c389-5510-432c-8caf-cc78e37f7dab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var my_btn_txt = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(my_btn_txt);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, videoStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  videoStream = stream;\n",
              "  var options = {  \n",
              "    mimeType : 'video/webm;codecs=vp9'  \n",
              "  };            \n",
              "  recorder = new MediaRecorder(stream, options);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('video');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      videoStream.getVideoTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... Please wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model_helper import segment\n",
        "from model_helper import ImageDataset\n",
        "import torch\n",
        "import imutils\n",
        "import numpy\n",
        "import torchvision\n",
        "import glob\n",
        "\n",
        "\n",
        "#pretrained model\n",
        "pretrained_model = \"/content/drinks-trained-weights.pth\"\n",
        "\n",
        "num_classes = 4\n",
        "model = segment(num_classes)\n",
        "model.load_state_dict(torch.load(pretrained_model))\n",
        "model.eval()\n",
        "\n",
        "#labels for objects and colors for bounding boxes\n",
        "labels = {0: 'background', 1: 'Water', 2: 'Soda', 3: 'Pineapple Juice'}\n",
        "colors = {0: (0,0,0), 1: (255,102,102), 2: (51,51,255), 3: (51,255,51)}\n",
        "\n",
        "cap = cv2.VideoCapture(video_file_test) \n",
        "\n",
        "#frame array to capture frames to convert back to video later\n",
        "frame_array = []\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    ret, frame = cap.read() \n",
        "\n",
        "    #if no frames left, break the loop\n",
        "    if not ret: \n",
        "      break\n",
        "\n",
        "    #convert image to tensor\n",
        "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32) / 255\n",
        "    image = torchvision.transforms.ToTensor()(image)\n",
        "    predictions = model([image])[0]\n",
        "\n",
        "    #loop to add bounding box and text for detection\n",
        "    for box, label, score in zip(predictions['boxes'], predictions['labels'], predictions['scores']):\n",
        "        label = label.item()\n",
        "        if label == 0 or score < 0.85:\n",
        "            continue\n",
        "        x_min, y_min, x_max, y_max = box.int().tolist()\n",
        "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), colors[label], 2)\n",
        "        cv2.putText(frame, f\"{labels[label]} {score.item():.2f}\", (x_min, y_min-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[label], 2)\n",
        "\n",
        "\n",
        "    # show modified frame\n",
        "    #cv2_imshow(frame)\n",
        "\n",
        "    #verify height and width\n",
        "    #print(frame.shape)\n",
        "\n",
        "    frame_array.append(frame)\n",
        "\n",
        "\n",
        "#convert back to video\n",
        "#verified above that width by height is 640x480\n",
        "result = \"/content/Video/video_demo.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = 30\n",
        "frame_width = 640\n",
        "frame_height = 480\n",
        "output = cv2.VideoWriter(result,fourcc,fps,(frame_width,frame_height))\n",
        "for i in range(len(frame_array)):\n",
        "    output.write(frame_array[i])\n",
        "output.release()"
      ],
      "metadata": {
        "id": "whpEabq7lAH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}